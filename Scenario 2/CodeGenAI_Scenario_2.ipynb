{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 2: Educational Tools**\n",
        "\n",
        "CodeGenie can be integrated into educational platforms to assist students in learning programming languages. Students can input their code assignments or projects, and CodeGenie will provide insights into code efficiency, syntax correctness, and logical flow. Additionally, it can offer suggestions for improvement and highlight specific parts of the code that are particularly well-written or problematic. This helps students learn to write clean, efficient, and error-free code, improving their coding skills and technic\n",
        "\n"
      ],
      "metadata": {
        "id": "p3IpgIXTs9Ih"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ3EygrrZExd",
        "outputId": "8fbad312-f3ee-4d68-e698-58b14951a373",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git@refs/pull/25740/head\n",
            "  Cloning https://github.com/huggingface/transformers.git (to revision refs/pull/25740/head) to /tmp/pip-req-build-dgjimyhy\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-dgjimyhy\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git@refs/pull/25740/head accelerate\n",
        "!pip install streamlit -q\n",
        "!pip install accelerate\n",
        "!pip install bitsandbytes\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile CodeModel.py\n",
        "\n",
        "# CodeModel.py\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
        "import torch\n",
        "import streamlit as st\n",
        "import re\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model_id = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        device_map=\"auto\",\n",
        "        quantization_config=bnb_config,\n",
        "        torch_dtype=torch.float16\n",
        "    )\n",
        "\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "    return pipe, tokenizer\n",
        "\n",
        "pipe, tokenizer = load_model()\n",
        "\n",
        "\n",
        "\n",
        "def generate_code(user):\n",
        "\n",
        "    def truncate_to_last_sentence(text):\n",
        "        # Remove hanging bullet like \"19.\" at end\n",
        "        match = re.search(r\"(.*?)(\\n\\d+\\.\\s*)?$\", text.strip(), re.DOTALL)\n",
        "        if match:\n",
        "            text = match.group(1)\n",
        "\n",
        "        # Now trim to last full sentence\n",
        "        if '.' in text:\n",
        "            last_period = text.rfind('.')\n",
        "            return text[:last_period + 1].strip()\n",
        "        return text.strip()\n",
        "\n",
        "\n",
        "    # system = \"You are CodeGenie, a concise programming tutor. Summarize what the code does, evaluate logic and style, then suggest clear fixes.\"\n",
        "    system = \"You are CodeGenie, a concise programming tutor. Summarize what the code does, evaluate logic and style, then suggest clear fixes.\"\n",
        "    '''user = \"\"\"Analyze this Python function and give feedback:\n",
        "\n",
        "    def add(a, b):\n",
        "      return a + b\"\"\"'''\n",
        "    prompt = f\"<s><<SYS>>\\n{system}\\n<</SYS>>\\n\\n{user}\"\n",
        "\n",
        "    prompt_tokens = tokenizer(prompt, return_tensors=\"pt\").input_ids.shape[-1]\n",
        "    max_total_tokens = 256\n",
        "    max_new_tokens = max(32, max_total_tokens - prompt_tokens)\n",
        "\n",
        "    sequences = pipe(\n",
        "        prompt,\n",
        "        do_sample=True,\n",
        "        top_k=10,\n",
        "        temperature=0.1,\n",
        "        top_p=0.95,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        add_special_tokens=False\n",
        "    )\n",
        "\n",
        "    generated = sequences[0]['generated_text']\n",
        "    if prompt in generated:\n",
        "        result = generated.replace(prompt, \"\").strip()\n",
        "    else:\n",
        "        # In case model doesn't echo prompt, just return from the first new line\n",
        "        result = generated.split('\\n', 1)[-1].strip()\n",
        "\n",
        "    result = truncate_to_last_sentence(result)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "89uaW1SKwXQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import time\n",
        "from CodeModel import generate_code\n",
        "st.header(\"CodeGenie: AI-powered code assistant\")\n",
        "\n",
        "with st.form(\"my_form\"):\n",
        "    user_input = st.text_area(\"Enter your text prompt below and click the button to submit.\")\n",
        "    submit = st.form_submit_button(label=\"Submit text prompt\")\n",
        "\n",
        "if submit:\n",
        "    with st.spinner(text=\"Generating code... It may take some time\"):\n",
        "        code = generate_code(user=user_input)\n",
        "        print(code)\n",
        "        st.code(code, language='python')\n",
        "    st.sidebar.markdown(\"## Guide\")\n",
        "    st.sidebar.info(\"This tool uses CodeLlama 7B parameters\")"
      ],
      "metadata": {
        "id": "egN6TqDJ1xjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "rJtr4HGZ2J7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Copy that number and paste it on the website as password on next cell**"
      ],
      "metadata": {
        "id": "6QHD4aPq2XC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Click \"your url is:\" link and paste that number**\n"
      ],
      "metadata": {
        "id": "C5g5Mi_f2YDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "d7POwhm12Q49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JVsIzYAW3IlB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}